Create a 5-page PowerPoint presentation for an HTML Chunk Search Application:

PAGE 1 - INTRODUCTION:
Title: "HTML Chunk Search Application - Overview"
Content: Task is to build a web app that searches website content using semantic search. Users enter a URL and query to find relevant content chunks. Solution: Full-stack app with React frontend and Django REST API backend. Uses semantic search with vector embeddings (sentence-transformers), intelligent HTML parsing, tokenization/chunking, and hybrid scoring (semantic + keyword matching). Key features: Modern responsive UI, real-time URL fetching/indexing, top 10 ranked results, Pinecone vector database for scalable semantic search.

PAGE 2 - FRONTEND DESIGN:
Title: "Frontend Implementation - React UI/UX"
Content: Built with React 18 and Create React App. UI/UX: Clean modern interface with intuitive two-input search form (URL + query), real-time loading states, error handling, responsive design. Key components: SearchForm.js (input validation), ResultsDisplay.js (results with expandable previews). User experience: Simple flow (Enter URL → Enter Query → Search), visual feedback, clear errors, expandable result cards with relevance scores and highlighted keywords.

PAGE 3 - BACKEND LOGIC:
Title: "Backend Architecture - Django & Processing Pipeline"
Content: Framework: Django 4.2 with Django REST Framework. HTML Processing Pipeline: (1) URL Fetching with HTTP requests and error handling, (2) HTML Parsing using BeautifulSoup4 - removes scripts/styles/navigation, focuses on main content, cleans citations, (3) Tokenization with Hugging Face transformers AutoTokenizer - 500 tokens per chunk, preserves word boundaries, fallback to word-based chunking, (4) Embedding Generation with sentence-transformers all-MiniLM-L6-v2 model - 384-dimensional normalized vectors. API Endpoints: POST /api/fetch/ (indexes content), POST /api/search/ (semantic search with hybrid scoring).

PAGE 4 - VECTOR DATABASE:
Title: "Vector Storage & Search Implementation"
Content: Storage: Pinecone vector database - managed cloud storage, serverless AWS architecture, automatic index creation, per-URL indexing with chunk-level granularity. Semantic Search: Model is sentence-transformers/all-MiniLM-L6-v2 (384 dims), Pinecone for vector storage, uses cosine similarity. Hybrid Scoring combines: semantic similarity from Pinecone (30% weight), keyword matching ratio (70% weight), exact phrase matching (99% score), position weighting (+0.1 for early chunks), first chunk bonus. Returns top 10 results by combined relevance. Advantages: Scalable cloud storage, fast semantic search, automatic index management, URL filtering support.

PAGE 5 - CONCLUSION:
Title: "Challenges, Learnings & Future Improvements"
Content: Challenges: (1) Memory management - large ML models caused worker timeouts, solved with lazy loading and CPU-only PyTorch, (2) Import errors - AutoTokenizer issues, solved with fallbacks and model's built-in tokenizer, (3) CORS configuration - Vercel/Render cross-origin, solved with comprehensive headers, (4) Build optimization - slow deployments, solved with optimized build commands, (5) Pinecone integration - API key management and index configuration, solved with environment variables and automatic index creation. Lessons: Lazy loading importance, robust error handling, environment-based config, hybrid scoring beats pure semantic, cloud vector DB provides scalability. Future improvements: Caching for frequently accessed URLs, multi-URL support, batch processing, UI filters/sorting, larger models, Docker containerization, advanced search features.

Design: Professional color scheme (blues/grays/whites), include code snippets/diagrams, concise bullet points, icons/graphics, consistent styling.

